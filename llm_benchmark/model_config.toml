[llama_3_8b]
bos_token_id = 128000
eos_token_id = 128001
hidden_size = 4096
intermediate_size = 14336
num_attention_heads = 32
num_hidden_layers = 32
num_key_value_heads = 8
vocab_size = 128256

[llama_3_70b]
bos_token_id = 128000
eos_token_id = 128001
hidden_size = 8192
intermediate_size = 28672
num_attention_heads = 64
num_hidden_layers = 80
num_key_value_heads = 8
vocab_size = 128256

