# 2 GPUS
[[configs]]  # completed
tp = 2
dp = 1
pp = 1
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 1  # OOM with larger batch size

# tp=2, dp=2, pp=1, mbz=1 fails :/

# 4 GPUs

[[configs]]  # completed
tp = 4
dp = 1
pp = 1
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 4  # OOM with larger maybe?

# 8 GPUs

# tp=2, dp=4, pp=1, mbz=2 OOM

[[configs]]  # completed
tp = 4
dp = 1
pp = 2
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 4  # OOM with larger?

[[configs]]  # not tried yet
tp = 4
dp = 1
pp = 2
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 8

[[configs]]  # completed
tp = 4
dp = 2
pp = 1
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 2

[[configs]]  # not tried yet
tp = 4
dp = 2
pp = 1
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 4

# 4 nodes

[[configs]]  # not tried yet
tp = 4
dp = 1
pp = 4
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 8

[[configs]]  # not tried yet
tp = 4
dp = 1
pp = 4
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 16

[[configs]]  # not tried yet
tp = 4
dp = 1
pp = 4
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 16

[[configs]]  # not tried yet
tp = 4
dp = 2
pp = 2
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 4

[[configs]]  # not tried yet
tp = 4
dp = 2
pp = 2
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 8

[[configs]]  # not tried yet
tp = 4
dp = 2
pp = 2
model = "llama_3_8b"
sequence_length = 4096
micro_batch_size = 16
